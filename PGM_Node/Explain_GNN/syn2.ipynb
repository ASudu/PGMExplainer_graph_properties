{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import models\n",
    "import numpy as np\n",
    "import torch\n",
    "import configs\n",
    "import pgm_explainer as pe\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "from pgmpy.estimators.CITests import chi_square\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "import argparse\n",
    "    \n",
    "def arg_parse():\n",
    "    parser = argparse.ArgumentParser(description=\"Explainer arguments.\")\n",
    "\n",
    "    parser.add_argument(\n",
    "            \"--bmname\", dest=\"bmname\", help=\"Name of the benchmark dataset\"\n",
    "        )\n",
    "    parser.add_argument(\"--dataset\", dest=\"dataset\", help=\"Input dataset.\")\n",
    "    parser.add_argument(\"--ckptdir\", dest=\"ckptdir\", help=\"Model checkpoint directory\")\n",
    "    parser.add_argument(\n",
    "            \"--gpu\",\n",
    "            dest=\"gpu\",\n",
    "            action=\"store_const\",\n",
    "            const=True,\n",
    "            default=False,\n",
    "            help=\"whether to use GPU.\",\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--node-start\", dest=\"node_start\", type=int, help=\"Index of starting node.\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--node-end\", dest=\"node_end\", type=int, help=\"Index of ending node.\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--num-perturb-samples\", dest=\"num_perturb_samples\", type=int, help=\"Number of perturbed sample using to generate explanations.\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--top-node\", dest=\"top_node\", type=int, help=\"Number of nodes in explanation.\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--epochs\", dest=\"num_epochs\", type=int, help=\"Number of epochs to train.\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--hidden-dim\", dest=\"hidden_dim\", type=int, help=\"Hidden dimension\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--output-dim\", dest=\"output_dim\", type=int, help=\"Output dimension\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--num-gc-layers\",\n",
    "            dest=\"num_gc_layers\",\n",
    "            type=int,\n",
    "            help=\"Number of graph convolution layers before each pooling\",\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--bn\",\n",
    "            dest=\"bn\",\n",
    "            action=\"store_const\",\n",
    "            const=True,\n",
    "            default=False,\n",
    "            help=\"Whether batch normalization is used\",\n",
    "        )\n",
    "    parser.add_argument(\"--dropout\", dest=\"dropout\", type=float, help=\"Dropout rate.\")\n",
    "    parser.add_argument(\n",
    "            \"--method\", dest=\"method\", type=str, help=\"Method. Possible values: base, att.\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--nobias\",\n",
    "            dest=\"bias\",\n",
    "            action=\"store_const\",\n",
    "            const=False,\n",
    "            default=True,\n",
    "            help=\"Whether to add bias. Default to True.\",\n",
    "        )\n",
    "    \n",
    "        # Explainer\n",
    "   \n",
    "    \n",
    "\n",
    "    parser.set_defaults(\n",
    "            ckptdir=None,\n",
    "            dataset=\"syn1\",\n",
    "            opt=\"adam\",  \n",
    "            opt_scheduler=\"none\",\n",
    "            lr=0.1,\n",
    "            clip=2.0,\n",
    "            batch_size=20,\n",
    "            num_epochs=100,\n",
    "            hidden_dim=20,\n",
    "            output_dim=20,\n",
    "            num_gc_layers=3,\n",
    "            method=\"base\",\n",
    "            dropout=0.0,\n",
    "            node_start = None,\n",
    "            node_end = None,\n",
    "            num_perturb_samples = 100,\n",
    "            top_node = None\n",
    "        )\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_args = arg_parse()\n",
    "args= prog_args.parse_args(['--dataset','syn2','--num-perturb-samples', '900','--top-node', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "A, X = utils.load_XA(args.dataset, datadir = \"../Generate_XA_Data/XAL\")\n",
    "L = utils.load_labels(args.dataset, datadir = \"../Generate_XA_Data/XAL\")\n",
    "num_classes = max(L) + 1\n",
    "input_dim = X.shape[1]\n",
    "num_nodes = X.shape[0]\n",
    "ckpt = utils.load_ckpt(args)\n",
    "\n",
    "print(\"input dim: \", input_dim, \"; num classes: \", num_classes)\n",
    "    \n",
    "model = models.GcnEncoderNode(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        embedding_dim=args.output_dim,\n",
    "        label_dim=num_classes,\n",
    "        num_layers=args.num_gc_layers,\n",
    "        bn=args.bn,\n",
    "        args=args,\n",
    "        )\n",
    "model.load_state_dict(ckpt[\"model_state\"]) \n",
    "pred = ckpt[\"save_data\"][\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of node to explain in this dataset is from 300 to 700\n",
    "nodes_to_explain = list(range(400,700,5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the explainer\n",
    "explainer = pe.Node_Explainer(model, A, X, pred, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pylab as plt\n",
    "\n",
    "def pgm_draw_nx(pgm_explanation):\n",
    "    print(\"Draw pgm explaination using networkx\")\n",
    "    nx.draw(pgm_explanation, with_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "def PGM_construct(pgm_explanation, target_name):\n",
    "    loc = [(0, 0), (-5, -5), (5, -5), (5, 5), (-5,5)]\n",
    "    pos = dict(zip(pgm_explanation.nodes(), loc))\n",
    "    color_dict = dict(zip(range(pred.shape[2]), ['y','b','m','r']))\n",
    "    color = [color_dict[ np.argmax(pred[0,int(node),:])] for node in pgm_explanation.nodes()]\n",
    "    name_dict = [r'$A$',r'$B$',r'$C$',r'$D$',r'$E$']\n",
    "    name = dict(zip(pgm_explanation.nodes(), name_dict))\n",
    "\n",
    "    # gt_graph = nx.Graph()\n",
    "    # gt_graph.add_nodes_from(pos.keys(), size=50)\n",
    "    # edges_list = [('300', '301'),('301', '302'),('302', '300'),('303', '300'),('304', '300')]\n",
    "    # gt_graph.add_edges_from(edges_list)\n",
    "\n",
    "    # print(\"Ground truth explaination of node \", name[target_name])\n",
    "    # figure1, ax1 = plt.subplots(figsize = (4,4))\n",
    "    # ax1.axis('off')\n",
    "    # nx.draw_networkx_nodes(gt_graph,pos,node_size=400,node_color= color)\n",
    "    # nx.draw_networkx_edges(gt_graph,pos,\n",
    "    #                     edgelist= edges_list,\n",
    "    #                     width=2.0,alpha=1)\n",
    "    # nx.draw_networkx_labels(gt_graph,pos,name,font_size=18, font_family = 'serif', font_weight = 'normal',\n",
    "    #                         font_color = 'w')\n",
    "\n",
    "    # # filename = 'view/motif_' + str(explained_node)+ '.jpg' \n",
    "    # # figure1.savefig(filename, dpi=90, bbox_inches='tight')\n",
    "\n",
    "    print(\"PGM explaination of node \", name[target_name])\n",
    "\n",
    "    figure2, ax = plt.subplots(figsize = (4,4))\n",
    "    ax.axis('off')\n",
    "    nx.draw_networkx_nodes(pgm_explanation,pos,node_size=400,node_color= color)\n",
    "    nx.draw_networkx_edges(pgm_explanation,pos,\n",
    "                        edgelist= pgm_explanation.edges,\n",
    "                        connectionstyle='arc3, rad = 0.2',\n",
    "                        width=2.0,alpha=0.8)\n",
    "    nx.draw_networkx_labels(pgm_explanation,pos,name,font_size=18, font_family = 'serif', font_color = 'w')\n",
    "    figure2.show()\n",
    "\n",
    "    # filename = 'view/pgm_' + str(explained_node)+ '.jpg' \n",
    "    # figure2.savefig(filename, dpi=90, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = nodes_to_explain[0]\n",
    "\n",
    "print(f\"--------------------------- Node {target} ---------------------------\")\n",
    "# Explaining the target node\n",
    "subnodes, data, stats = explainer.explain(target, num_samples = 900, top_node = 3, pred_threshold = 0.2)\n",
    "# Markov Blanket of target node\n",
    "print(\"MK-blanket of target node:\", subnodes)\n",
    "\n",
    "# Generating the Probabilistic Graph\n",
    "print(\"Generate the PGM\")\n",
    "pgm_explanation = explainer.pgm_generate(target, data, stats, subnodes)\n",
    "print(\"PGM Nodes: \", pgm_explanation.nodes())\n",
    "print(\"PGM Edges: \", pgm_explanation.edges())\n",
    "\n",
    "# Conversion of target names for preventing type mismatch\n",
    "print(\"The variables in the PGM is 'str' while the nodes' names in the dataset is 'int' so we convert them for convenience\")\n",
    "target_name = str(target)\n",
    "explaining_nodes = [node for node in pgm_explanation.nodes() if node != target_name]\n",
    "\n",
    "# Computing marginal probability of target prediction with no observation\n",
    "print(\"Compute marginal probability of the target prediction with no observation\")\n",
    "marginal_prob = explainer.pgm_conditional_prob(target_name, pgm_explanation, [])\n",
    "print(marginal_prob)\n",
    "\n",
    "# Computing other probabilities\n",
    "target_label = np.argmax(pred[0,target])\n",
    "print(\"Target's label is: \", target_label)\n",
    "for num_of_evidence in range(len(explaining_nodes)):\n",
    "    cond_prob = explainer.pgm_conditional_prob(target_name, pgm_explanation, explaining_nodes[0:num_of_evidence+1])\n",
    "    print(\"Probability that the target's label is {} given {} is {}\".format(target_label,\n",
    "                                                                            explaining_nodes[0:num_of_evidence+1],\n",
    "                                                                        cond_prob))\n",
    "\n",
    "\n",
    "# Drawing pgm explanation\n",
    "pgm_draw_nx(pgm_explanation)\n",
    "PGM_construct(pgm_explanation, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to analyze the graph properties\n",
    "def betweeness_centrality_single_sink(graph,node_to_explain, v):\n",
    "    \n",
    "    bc = 0\n",
    "    diameter = nx.diameter(graph)\n",
    "    nodes = list(graph.nodes())\n",
    "    for i in tqdm(range(len(nodes))):\n",
    "        paths_with_v = 0\n",
    "        paths = 0\n",
    "        if nodes[i]!=node_to_explain and nodes[i]!=v:\n",
    "            # print(f\"Centrality of {v} chosen node {i}\")\n",
    "            if nx.has_path(graph,nodes[i],node_to_explain):\n",
    "                # Find all paths between i and the node_to_explain\n",
    "                all_paths = nx.all_simple_paths(graph,nodes[i],node_to_explain,diameter)\n",
    "                # print(\"All paths obtained\")\n",
    "\n",
    "                # Find the paths containing v\n",
    "                for path in all_paths:\n",
    "                    # print(\"loop entered\")\n",
    "                    # print(paths)\n",
    "                    paths += 1\n",
    "                    if v in path:\n",
    "                        paths_with_v += 1\n",
    "\n",
    "                # Add this to bc\n",
    "                bc += paths_with_v/paths\n",
    "    \n",
    "    return bc\n",
    "\n",
    "def normalize(A):\n",
    "    scale_factor = A.max() - A.min()\n",
    "    B = np.ones_like(A)*A.min()\n",
    "\n",
    "    A = (A - B)/scale_factor\n",
    "    return A\n",
    "\n",
    "def centrality(G, stats,node_to_explain,variation=1,p_threshold=0.05):\n",
    "    \n",
    "    # # Obtain the importance score for all nodes\n",
    "    # bc = {}\n",
    "    # for v in list(G.nodes()):\n",
    "    #     print(f\"Calculating centrality for {v}\")\n",
    "    #     if v!=node_to_explain:\n",
    "    #         bc.update({v : betweeness_centrality_single_sink(G,node_to_explain, v)})\n",
    "    \n",
    "    # bc.update({node_to_explain: 1})\n",
    "    # bc ={}\n",
    "    if variation==1:\n",
    "        bc = nx.betweenness_centrality(G)\n",
    "    elif variation==2:\n",
    "        sources = [node_to_explain]\n",
    "        targets = [v for v in list(G.nodes()) if v!=node_to_explain]\n",
    "        bc = nx.betweenness_centrality_subset(G,sources,targets)\n",
    "\n",
    "    # Get the two vectors we have to compare for coherence calculation\n",
    "    # We are fixing the values as 0 for the nodes not in \"nodes_to_consider\"\n",
    "    A1 = []\n",
    "    B1 = []\n",
    "    for i in list(G.nodes()):\n",
    "        A1.append(bc.get(i))\n",
    "        B1.append(1 - (stats.get(i)))\n",
    "\n",
    "    A1 = normalize(np.array(A1))\n",
    "    B1 = normalize(np.array(B1))\n",
    "    # print(f\"A1: {len(A1)}\")\n",
    "    # print(f\"B1: {len(B1)}\")\n",
    "    # return 1\n",
    "    # Calculating coherence\n",
    "    diff = np.subtract(np.array(A1), np.array(B1))\n",
    "    if(np.array_equal(A1,B1) == False):\n",
    "        return 1/(np.linalg.norm(diff,2))**2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def graph_prop(graph, stats, target, p_threshold,variation):\n",
    "    v = graph.number_of_nodes()\n",
    "    e = graph.number_of_edges()\n",
    "    avg_degree = float('%.3f'%(2*e/v))\n",
    "    diameter = nx.diameter(graph)\n",
    "    sparsity = float('%.3f'%(2*e/(v*(v-1))))\n",
    "    coherence_int = float('%.3f'%(centrality(graph,stats, target, variation, p_threshold)))\n",
    "\n",
    "    return [v,e,avg_degree,diameter,sparsity,coherence_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the node mask obtained\n",
    "# \"stats\" has the n-hop neighbors of the target node and the corresponding p-values\n",
    "# The dependent neighbors are chosen based on comparing the p-value to a certain threshold\n",
    "# For this reason we use the p-values as an indicator of importance of the node\n",
    "# We define node_importance_by_exp = (1-p)\n",
    "\n",
    "graph_data = []\n",
    "variation = 1\n",
    "\n",
    "# Explaining each target node\n",
    "for target in nodes_to_explain:\n",
    "    # Explaining the target node\n",
    "    p_threshold = 0.05  # Default threshold for p-value according to statistics\n",
    "\n",
    "    # We set top_node as None since we want to check how compact the explanations are without restricting its size\n",
    "    _, _, stats = explainer.explain(target, num_samples = 900, p_threshold=p_threshold, pred_threshold = 0.2)\n",
    "\n",
    "    # Original network\n",
    "    G = nx.from_numpy_array(explainer.A)\n",
    "    # Considered neighbors\n",
    "    nbors = list(stats.keys())\n",
    "    # nodes_to_consider = []\n",
    "    # # Masking the nodes\n",
    "    # for v in nbors:\n",
    "    #     if stats.get(v) < p_threshold:\n",
    "    #         nodes_to_consider.append(v)\n",
    "\n",
    "    # Vertex induced subgraph that acts as the explanation\n",
    "    exp_subgraph = nx.induced_subgraph(G, nbors)\n",
    "\n",
    "    # All properties obtained\n",
    "    graph_data.append(graph_prop(exp_subgraph,stats, target, p_threshold,variation))\n",
    "\n",
    "# Convert the above data into a data frame\n",
    "df = pd.DataFrame(graph_data, columns=[\"Order\",\"Size\",\"Average Degree\",\"Diameter\",\"Sparsity\",\"Coherence\"])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Coherence\n",
    "coh_int = list(df[\"Coherence\"])\n",
    "coh = [float(i)/max(coh_int) for i in coh_int]\n",
    "\n",
    "df = df.replace(coh_int, coh)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the node mask obtained\n",
    "# \"stats\" has the n-hop neighbors of the target node and the corresponding p-values\n",
    "# The dependent neighbors are chosen based on comparing the p-value to a certain threshold\n",
    "# For this reason we use the p-values as an indicator of importance of the node\n",
    "# We define node_importance_by_exp = (1-p)\n",
    "\n",
    "graph_data1 = []\n",
    "variation = 2\n",
    "\n",
    "# Explaining each target node\n",
    "for target in nodes_to_explain:\n",
    "    # Explaining the target node\n",
    "    p_threshold = 0.05  # Default threshold for p-value according to statistics\n",
    "\n",
    "    # We set top_node as None since we want to check how compact the explanations are without restricting its size\n",
    "    _, _, stats = explainer.explain(target, num_samples = 900, p_threshold=p_threshold, pred_threshold = 0.2)\n",
    "\n",
    "    # Original network\n",
    "    G = nx.from_numpy_array(explainer.A)\n",
    "    # Considered neighbors\n",
    "    nbors = list(stats.keys())\n",
    "    # nodes_to_consider = []\n",
    "    # # Masking the nodes\n",
    "    # for v in nbors:\n",
    "    #     if stats.get(v) < p_threshold:\n",
    "    #         nodes_to_consider.append(v)\n",
    "\n",
    "    # Vertex induced subgraph that acts as the explanation\n",
    "    exp_subgraph = nx.induced_subgraph(G, nbors)\n",
    "\n",
    "    # All properties obtained\n",
    "    graph_data1.append(graph_prop(exp_subgraph,stats, target, p_threshold,variation))\n",
    "\n",
    "# Convert the above data into a data frame\n",
    "df1 = pd.DataFrame(graph_data, columns=[\"Order\",\"Size\",\"Average Degree\",\"Diameter\",\"Sparsity\",\"Coherence\"])\n",
    "\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sparsity\n",
    "x = list(range(len(df)))\n",
    "sparse = list(df['Sparsity'])\n",
    "def_sparse = list(np.ones(len(df))*0.5)\n",
    "mean_sparse = list(np.ones(len(df))*df['Sparsity'].mean())\n",
    "plt.figure(figsize=(20,6), dpi = 500)\n",
    "plt.gca().grid(True)\n",
    "plt.gca().set_facecolor((1, 1, 0.8))\n",
    "plt.plot(x, sparse, label='sparsity')\n",
    "# plt.plot(x,def_sparse, label = 'Max edge density for sparse graphs')\n",
    "plt.plot(x,mean_sparse, label = 'Average sparsity', color='k')\n",
    "\n",
    "sp_mean = df['Sparsity'].mean()\n",
    "sp_std = df['Sparsity'].std()\n",
    "y1 = sp_mean - sp_std\n",
    "y_1 = y1 - sp_std\n",
    "y2 = sp_mean + sp_std\n",
    "y_2 = y2 + sp_std\n",
    "plt.axhspan(y_1, y_2, color='red', alpha=0.3)\n",
    "plt.axhspan(y1, y2, color='green', alpha=0.3)\n",
    "\n",
    "plt.title('syn_2 dataset sparsity of explanations', fontsize=12)\n",
    "plt.legend(prop={'size':10})\n",
    "plt.ylabel(\"Sparsity\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.savefig(fname= \"D:\\D_Drive\\Github\\Thesis\\PGMExplainer_graph_properties\\PGM_Node\\Explain_GNN\\plots\\syn2_sparsity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Coherence\n",
    "coh = list(df['Coherence'])\n",
    "mean_coh = list(np.ones(len(df))*df['Coherence'].mean())\n",
    "plt.figure(figsize=(20,6), dpi = 500)\n",
    "plt.gca().grid(True)\n",
    "plt.gca().set_facecolor((1, 1, 0.8))\n",
    "plt.plot(x, coh, label='coherence')\n",
    "plt.plot(x,mean_coh, label = 'Average coherence', color='k')\n",
    "\n",
    "coh_mean = df['Coherence'].mean()\n",
    "coh_std = df['Coherence'].std()\n",
    "y1 = coh_mean - coh_std\n",
    "y_1 = y1 - coh_std\n",
    "y2 = coh_mean + coh_std\n",
    "y_2 = y2 + coh_std\n",
    "plt.axhspan(y_1, y_2, color='red', alpha=0.3)\n",
    "plt.axhspan(y1, y2, color='green', alpha=0.3)\n",
    "\n",
    "plt.title('syn_2 dataset coherence of explanations', fontsize=12)\n",
    "plt.legend(prop={'size':10})\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.savefig(fname= \"D:\\D_Drive\\Github\\Thesis\\PGMExplainer_graph_properties\\PGM_Node\\Explain_GNN\\plots\\syn2_coherence\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
